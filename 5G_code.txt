import numpy as np
import pandas as pd
import keras
from keras import layers
from matplotlib import pyplot as plt
from matplotlib.ticker import FormatStrFormatter

# Define the number of time steps
TIME_STEPS = 12  # Example value, adjust as needed


file_train_root = "E:/Users/Δημήτρης Τσάμπρας/Desktop/5G/DATA/train_formated.csv"
file_test_root = "E:/Users/Δημήτρης Τσάμπρας/Desktop/5G/DATA/test_formated.csv"
#
# fields = ['var1', 'var2', 'var3', 'var4', 'var5', 'var6', 'var7',
#         'var8', 'var9', 'var10', 'var11', 'var12', 'var13', 'var14',
#         'var15', 'var16', 'var17', 'var18', 'var19', 'var20',
#          'var21', 'var22', 'var23', 'var24', 'var25', 'var26',
#          'var27', 'var28', 'var29', 'var30', 'var31', 'var32',
#          'var33', 'var34', 'var35', 'var36', 'var37', 'var38']

# read only the specified column
# read and display var1
df_0 = pd.read_csv(file_train_root, usecols=[0])
print(df_0)
# read and display var 2
df_1 = pd.read_csv(file_train_root, usecols=[1])
print(df_1)

df_testset0 = pd.read_csv(file_test_root, usecols=[0])
print(df_testset0)
#df_testset1 = pd.read_csv(file_test_root, usecols=[1])
#print(df_testset1)

# print(df_trainset)
# print(df_testset)

# plot var1
fig, ax = plt.subplots()
df_0.plot(legend=False, ax=ax)
plt.show()

# plot var2
fig, ax = plt.subplots()
df_1.plot(legend=False, ax=ax)
plt.show()

#plot var1 test
#fig, ax = plt.subplots()
#df_testset0.plot(legend=False, ax=ax)
#plt.show()

# plot var2 test
#fig, ax = plt.subplots()
#df_testset1.plot(legend=False, ax=ax)
#plt.show()

#var 1
training_mean = df_0.mean()
training_std = df_0.std()
df_training_value = (df_0 - training_mean) / training_std
print("Number of training samples:", len(df_training_value))

# Generated training sequences for use in the model.
def create_sequences(values, time_steps=TIME_STEPS):
    output = []
    for i in range(len(values) - time_steps + 1):
        output.append(values[i : (i + time_steps)])
    return np.stack(output)


x_train = create_sequences(df_training_value.values)
print("Training input shape: ", x_train.shape)

model = keras.Sequential(
    [
        layers.Input(shape=(x_train.shape[1], x_train.shape[2])),
        layers.Conv1D(
            filters=32,
            kernel_size=7,
            padding="same",
            strides=2,
            activation="relu",
        ),
        layers.Dropout(rate=0.2),
        layers.Conv1D(
            filters=16,
            kernel_size=7,
            padding="same",
            strides=2,
            activation="relu",
        ),
        layers.Conv1DTranspose(
            filters=16,
            kernel_size=7,
            padding="same",
            strides=2,
            activation="relu",
        ),
        layers.Dropout(rate=0.2),
        layers.Conv1DTranspose(
            filters=32,
            kernel_size=7,
            padding="same",
            strides=2,
            activation="relu",
        ),
        layers.Conv1DTranspose(filters=1, kernel_size=7, padding="same"),
    ]
)
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss="mse")
model.summary()

history = model.fit(
    x_train,
    x_train,
    epochs=50,
    batch_size=128,
    validation_split=0.1,
    callbacks=[
        keras.callbacks.EarlyStopping(monitor="val_loss", patience=5, mode="min")
    ],
)

plt.plot(history.history["loss"], label="Training Loss")
plt.plot(history.history["val_loss"], label="Validation Loss")
plt.legend()
plt.show()
